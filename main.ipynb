{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "CONFIGURATION",
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "qjYbxKYL79khAg2LaJVsju",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_FOLDER = 'videos4/projfiles'\n",
    "CSV_FILE_MUSIC = os.path.join(CSV_FOLDER, 'input', 'youtube_comments_audio.csv')\n",
    "CSV_FILE_VIDEO = os.path.join(CSV_FOLDER, 'input', 'youtube_comments_video.csv')\n",
    "# CSV_FILE_SPORT = os.path.join(CSV_FOLDER, 'input', 'youtube_comments_sport.csv')\n",
    "CSV_FILE_BETTERVIDEO = os.path.join(CSV_FOLDER, 'input', 'youtube_comments_bettervideo.csv')\n",
    "CSV_FILE_PATH = os.path.join(CSV_FOLDER, 'youtube_comments.csv')\n",
    "EMBEDDED_CSV_PATH = os.path.join(CSV_FOLDER, 'youtube_comments_embeded.csv')\n",
    "CLUSTERED_CSV_PATH = os.path.join(CSV_FOLDER, 'youtube_comments_clustered.csv')\n",
    "LABELED_CSV_PATH = os.path.join(CSV_FOLDER, 'youtube_comments_labeled.csv')\n",
    "BATCH_FILE = \"batch_input.jsonl\"\n",
    "OPENAI_MODEL = \"text-embedding-3-large\"\n",
    "RATE_LIMIT_DELAY = 0.00  # in seconds\n",
    "\n",
    "# --- OpenAI Client ---\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "1iP4qsGQAOhE3cwUJ3OKMJ",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def string_to_array(embedding_str):\n",
    "    \"\"\"Converts a string representation of an array to a NumPy array.\"\"\"\n",
    "    try:\n",
    "        # Remove brackets and split by comma\n",
    "        cleaned_str = embedding_str.strip('[]')\n",
    "        values = cleaned_str.split(',')\n",
    "        # Convert each value to float\n",
    "        return np.array([float(val.strip()) for val in values])\n",
    "    except:\n",
    "        return None  # Handle potential errors in parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "zQEtoRoM8BDoQvKXhfSNXD",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Categories used for the labeling\n",
    "category_dict = {\n",
    "    \"Vocal Performance\": 1,\n",
    "\n",
    "    \"Visual Performance\": 2,\n",
    "    \"Visual Performance - Stage Presence\": 2.1,\n",
    "    \"Visual Performance - Gestures\": 2.2,\n",
    "    \"Visual Performance - Movement\": 2.3,\n",
    "\n",
    "    \"Technical Production\": 3,\n",
    "    \"Technical Production - Video Quality\": 3.1,\n",
    "    \"Technical Production - Camera Work\": 3.2,\n",
    "    \"Technical Production - Lighting\": 3.3,\n",
    "\n",
    "    \"Overall Impression\": 4,\n",
    "    \"Overall Impression - Positive\": 4.1,\n",
    "    \"Overall Impression - Negative\": 4.2,\n",
    "    \"Overall Impression - Neutral\": 4.3,\n",
    "\n",
    "    \"Engagement/Connection\": 5,\n",
    "    \"Engagement/Connection - Personal Connection\": 5.1,\n",
    "    \"Engagement/Connection - Artist Connection\": 5.2,\n",
    "\n",
    "    \"Olympic games\": 6,\n",
    "\n",
    "    \"Implicit Visual Influence\": 7,\n",
    "\n",
    "    \"Playback usage\": 8\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "combine",
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# Preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ZilPB7gC2BfZwMDG69am07",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "IAPgmCv9CJz5O6r4QJJTj6",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "df_music = pd.read_csv(CSV_FILE_MUSIC, sep='\\t', quoting=csv.QUOTE_ALL, quotechar='\"', encoding='utf-8')\n",
    "df_video = pd.read_csv(CSV_FILE_VIDEO, sep='\\t', quoting=csv.QUOTE_ALL, quotechar='\"', encoding='utf-8')\n",
    "#df_sport = pd.read_csv(CSV_FILE_SPORT, sep='\\t', quoting=csv.QUOTE_ALL, quotechar='\"', encoding='utf-8')\n",
    "df_bettervideo = pd.read_csv(CSV_FILE_BETTERVIDEO, sep='\\t', quoting=csv.QUOTE_ALL, quotechar='\"', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Dh3oDlL0g8eKx9E5Kg9yAz",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "df_music['source_id'] = 1\n",
    "df_video['source_id'] = 2\n",
    "# df_sport['source_id'] = 2\n",
    "df_bettervideo['source_id'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "EEYr7C4cboZKBx1RDyUzwE",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_music, df_video, df_bettervideo], ignore_index=True) #add df_sport if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Uvv8sugQAl4z0DHgFRNpaW",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df, CSV_FILE_PATH)\n",
    "del df_music\n",
    "del df_video\n",
    "# del df_sport\n",
    "del df_bettervideo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Labeling",
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "hCwGBaftHhnPSvoHySBVbu",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b5/hxjnqzqj32l4jyk_bkplnc9w0000gn/T/ipykernel_2915/3726769479.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(CSV_FILE_PATH)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "p74sw6RuboI8Vut1JrFcuM",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a comment classifier. Your task is to categorize comments based on a predefined set of categories and return their numerical IDs as a Python list. You must ONLY output a list of integers, and nothing else. Do not include any category names or other text in your response.\"\"\"\n",
    "\n",
    "user_template = \"\"\"\n",
    "Here are the categories and their IDs:\n",
    "{category_dict}\n",
    "\n",
    "Please read the comment below and identify all relevant categories.  Return ONLY the numerical IDs of the relevant categories as a Python list.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "* **Identify Relevant Categories:** Determine which categories from the list above apply to the comment.\n",
    "* **Output Format:** Return ONLY a Python list containing the numerical IDs of the relevant categories. The list should look like this: `[ID1, ID2, ID3]` (e.g., `[1, 8]` or `[3]` or `[]`).\n",
    "* **Multiple Categories:** If multiple categories are relevant, include all their IDs in the list, separated by commas within the brackets.\n",
    "* **No Relevant Categories:** If no categories are relevant, return an empty list `[]`.\n",
    "* **Numerical IDs ONLY:**  Do NOT include category names or any other text in your response. Just the list of numerical IDs.\n",
    "\n",
    "**Example Outputs:**\n",
    "* For a comment belonging to categories 1 and 8: `[1, 8]`\n",
    "* For a comment belonging to category 3: `[3]`\n",
    "* For a comment belonging to no categories: `[]`\n",
    "\n",
    "**Comment Text:**\n",
    "{comment_text}\n",
    "\n",
    "Category(ies) ID:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "30WPH0vkJNmlwKMmb8LHYt",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def create_batch_input_files(df, category_dict, user_template, max_comments_per_batch=15000):\n",
    "    \"\"\"Creates multiple JSONL files for Batch API input with comment limit per batch.\"\"\"\n",
    "    total_rows = len(df)\n",
    "    batch_files = []\n",
    "    \n",
    "    # Calculate number of batches needed based on max comments per batch\n",
    "    num_batches = (total_rows + max_comments_per_batch - 1) // max_comments_per_batch\n",
    "    \n",
    "    for batch_num in range(num_batches):\n",
    "        start_idx = batch_num * max_comments_per_batch\n",
    "        end_idx = min((batch_num + 1) * max_comments_per_batch, total_rows)\n",
    "        batch_filename = f\"batch_input_{batch_num + 1}.jsonl\"\n",
    "        \n",
    "        # Get batch subset of DataFrame\n",
    "        batch_df = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"Creating batch {batch_num + 1}/{num_batches} with {len(batch_df)} comments\")\n",
    "        \n",
    "        with open(batch_filename, 'w') as f:\n",
    "            for index, row in batch_df.iterrows():\n",
    "                user_message = user_template.format(\n",
    "                    comment_text=row['comment_text'], \n",
    "                    category_dict=json.dumps(category_dict)\n",
    "                )\n",
    "                request_data = {\n",
    "                    \"custom_id\": str(index),\n",
    "                    \"method\": \"POST\",\n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\n",
    "                        \"model\": \"gpt-4o-mini\",\n",
    "                        \"messages\": [\n",
    "                            {\"role\": \"system\", \"content\": system_message},\n",
    "                            {\"role\": \"user\", \"content\": user_message}\n",
    "                        ],\n",
    "                        \"temperature\": 0.3,\n",
    "                        \"seed\": 42\n",
    "                    }\n",
    "                }\n",
    "                f.write(json.dumps(request_data) + '\\n')\n",
    "        \n",
    "        batch_files.append(batch_filename)\n",
    "        print(f\"Created batch file: {batch_filename}\")\n",
    "    \n",
    "    return batch_files\n",
    "\n",
    "def process_batch_results(output_file_path):\n",
    "    \"\"\"Process the batch results from the output file and return as a dictionary.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    with open(output_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            response_data = json.loads(line)\n",
    "            custom_id = response_data.get('custom_id')\n",
    "            \n",
    "            try:\n",
    "                # Navigate through the response structure\n",
    "                if ('response' in response_data and \n",
    "                    'body' in response_data['response']):\n",
    "                    \n",
    "                    # Parse the body as JSON\n",
    "                    body_str = response_data['response']['body']\n",
    "                    if isinstance(body_str, str):\n",
    "                        body = json.loads(body_str)\n",
    "                    else:\n",
    "                        body = body_str\n",
    "                    \n",
    "                    # Extract the content from the assistant's message\n",
    "                    if ('choices' in body and \n",
    "                        len(body['choices']) > 0 and \n",
    "                        'message' in body['choices'][0] and\n",
    "                        'content' in body['choices'][0]['message']):\n",
    "                        \n",
    "                        content = body['choices'][0]['message']['content']\n",
    "                        \n",
    "                        # Parse the content as a JSON array\n",
    "                        try:\n",
    "                            labels = json.loads(content)\n",
    "                            results[custom_id] = labels\n",
    "                        except json.JSONDecodeError:\n",
    "                            print(f\"Warning: Could not parse content as JSON for ID {custom_id}: {content}\")\n",
    "                            # If parsing fails, store the raw content\n",
    "                            results[custom_id] = content\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing result for ID {custom_id}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Processed {len(results)} results from batch\")\n",
    "    return results\n",
    "\n",
    "def process_batch_with_retries(client, batch_file, max_retries=3, retry_delay=60):\n",
    "    \"\"\"Process a single batch file with retries and better error handling.\"\"\"\n",
    "    print(f\"Processing batch file: {batch_file}\")\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Upload batch file\n",
    "            with open(batch_file, \"rb\") as f:\n",
    "                response = client.files.create(file=f, purpose=\"batch\")\n",
    "            input_file_id = response.id\n",
    "            \n",
    "            # Create batch\n",
    "            batch_response = client.batches.create(\n",
    "                input_file_id=input_file_id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window=\"24h\"\n",
    "            )\n",
    "            batch_id = batch_response.id\n",
    "            print(f\"Batch created with ID: {batch_id}\")\n",
    "            \n",
    "            # Monitor batch status\n",
    "            while True:\n",
    "                batch_status = client.batches.retrieve(batch_id)\n",
    "                print(f\"Batch status: {batch_status.status}\")\n",
    "                \n",
    "                if batch_status.status == \"completed\":\n",
    "                    output_file_id = batch_status.output_file_id\n",
    "                    output_file_response = client.files.content(output_file_id)\n",
    "                    output_file_path = f\"batch_output_{batch_id}.jsonl\"\n",
    "                    \n",
    "                    with open(output_file_path, 'w') as f:\n",
    "                        f.write(output_file_response.text)\n",
    "                    \n",
    "                    return process_batch_results(output_file_path)\n",
    "                \n",
    "                elif batch_status.status in [\"failed\", \"expired\", \"cancelled\"]:\n",
    "                    print(f\"Batch failed with status: {batch_status.status}\")\n",
    "                    if batch_status.error_file_id:\n",
    "                        error_file_response = client.files.content(batch_status.error_file_id)\n",
    "                        print(\"Error details:\", error_file_response.text)\n",
    "                    break\n",
    "                \n",
    "                time.sleep(60)  # Check every minute\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed with error: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                print(\"Max retries reached. Moving to next batch.\")\n",
    "                return {}\n",
    "    \n",
    "    return {}\n",
    "\n",
    "def process_all_batches(df, category_dict, user_template, client):\n",
    "    \"\"\"Process all batches with progress tracking and error handling.\"\"\"\n",
    "    print(\"Starting batch processing...\")\n",
    "    \n",
    "    # Create batch files\n",
    "    batch_files = create_batch_input_files(df, category_dict, user_template)\n",
    "    all_results = {}\n",
    "    processed_batches = 0\n",
    "    total_batches = len(batch_files)\n",
    "    \n",
    "    # Process each batch\n",
    "    for batch_file in batch_files:\n",
    "        processed_batches += 1\n",
    "        print(f\"\\nProcessing batch {processed_batches}/{total_batches}\")\n",
    "        \n",
    "        batch_results = process_batch_with_retries(client, batch_file)\n",
    "        all_results.update(batch_results)\n",
    "        \n",
    "        # Save intermediate results\n",
    "        intermediate_df = df.copy()\n",
    "        intermediate_df['comment_labels'] = intermediate_df.index.map(lambda x: all_results.get(str(x), []))\n",
    "        intermediate_df.to_csv(f\"intermediate_results_{processed_batches}.csv\")\n",
    "        print(f\"Saved intermediate results to: intermediate_results_{processed_batches}.csv\")\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#batch_results = process_batch_results('/data/notebook_files/projfiles/input/batch_67b701252b4c8190b77ec9e319c0b008_output.jsonl')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m all_results \u001b[38;5;241m=\u001b[39m process_all_batches(\u001b[43mdf\u001b[49m, category_dict, user_template, client)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Update DataFrame with final results\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment_labels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: all_results\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mstr\u001b[39m(x), []))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#batch_results = process_batch_results('/data/notebook_files/projfiles/input/batch_67b701252b4c8190b77ec9e319c0b008_output.jsonl')\n",
    "\n",
    "all_results = process_all_batches(df, category_dict, user_template, client)\n",
    "\n",
    "# Update DataFrame with final results\n",
    "df['comment_labels'] = df.index.map(lambda x: all_results.get(str(x), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "OWGSprFoTiQZogNkyzpGri",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df, LABELED_CSV_PATH)\n",
    "print(\"Labeling completed and saved to:\", LABELED_CSV_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "tags-process",
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# tags_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "4Dkxuviknm0UdmT35P608V",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(LABELED_CSV_PATH)\n",
    "import ast  # import ast module for literal evaluation of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "648TPFErnoXZtmaCYjao43",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def add_category_indicators(df, category_dict):\n",
    "    \"\"\"\n",
    "    Adds binary indicator columns (1/0) for each category to the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'comment_labels' column\n",
    "        category_dict (dict): Dictionary defining categories and their codes\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with additional binary category columns\n",
    "    \"\"\"\n",
    "    # Create new columns for each category, initialized with 0\n",
    "    for category_name in category_dict.keys():\n",
    "        df[f'has_{category_name}'] = 0\n",
    "    \n",
    "    # Process each row\n",
    "    for idx, row in df.iterrows():\n",
    "        labels_str = row['comment_labels']\n",
    "        labels_list = []\n",
    "        \n",
    "        # Parse the labels\n",
    "        if isinstance(labels_str, str):\n",
    "            try:\n",
    "                labels_list = ast.literal_eval(labels_str)\n",
    "                if not isinstance(labels_list, list):\n",
    "                    labels_list = []\n",
    "            except (ValueError, SyntaxError):\n",
    "                print(f\"Warning: Could not parse comment_labels string: '{labels_str}'. Treating as no labels.\")\n",
    "                labels_list = []\n",
    "        elif isinstance(labels_str, list):\n",
    "            labels_list = labels_str\n",
    "            \n",
    "        # Set indicators for present categories\n",
    "        if isinstance(labels_list, list):\n",
    "            for label in labels_list:\n",
    "                for cat_name, cat_code in category_dict.items():\n",
    "                    if label == cat_code:\n",
    "                        df.at[idx, f'has_{cat_name}'] = 1\n",
    "                        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "DYj3myYijBIg12r4WLmtzM",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Add binary category indicators\n",
    "df = add_category_indicators(df, category_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Kruskal–Wallis test",
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# Kruskal–Wallis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "DzsVMlG3Z7iQKAP36o1OuD",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "from ast import literal_eval  # converting strings to lists\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "4snqiwHgTtEjhHbhpJVvUC",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(LABELED_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "uT5BITGgmpLXUT2faPKsHw",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "\n",
    "def perform_kruskal_wallis_test(df, category_dict):\n",
    "    \"\"\"\n",
    "    Performs Kruskal-Wallis H-test for each category across different video sources.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'source_id' and binary category columns (has_*)\n",
    "        category_dict (dict): Dictionary defining categories and their codes\n",
    "    \"\"\"\n",
    "    kruskal_results = {}\n",
    "    \n",
    "    # Test each category\n",
    "    for category_name in category_dict.keys():\n",
    "        column_name = f'has_{category_name}'\n",
    "        if column_name not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        # Group data by source_id\n",
    "        category_presence_by_source = defaultdict(list)\n",
    "        for source in sorted(df['source_id'].unique()):\n",
    "            source_data = df[df['source_id'] == source][column_name].tolist()\n",
    "            category_presence_by_source[source] = source_data\n",
    "            \n",
    "        # Perform Kruskal-Wallis test\n",
    "        try:\n",
    "            h_statistic, p_value = kruskal(*[category_presence_by_source[s] for s in sorted(df['source_id'].unique())])\n",
    "            kruskal_results[category_name] = {\n",
    "                'H_statistic': h_statistic, \n",
    "                'p_value': p_value, \n",
    "                'groups_data': category_presence_by_source\n",
    "            }\n",
    "        except ValueError as e:\n",
    "            kruskal_results[category_name] = {\n",
    "                'H_statistic': np.nan, \n",
    "                'p_value': np.nan, \n",
    "                'error': str(e), \n",
    "                'groups_data': category_presence_by_source\n",
    "            }\n",
    "            \n",
    "    # Print results\n",
    "    print(\"Kruskal-Wallis Test Results for Category Distribution across Video Types:\\n\")\n",
    "    for category, result in kruskal_results.items():\n",
    "        print(f\"Category: {category}\")\n",
    "        if 'error' in result:\n",
    "            print(f\"  Error during Kruskal-Wallis test: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"  Kruskal-Wallis H-statistic: {result['H_statistic']:.4f}\")\n",
    "            print(f\"  P-value: {result['p_value']:.4f}\")\n",
    "            \n",
    "            if result['p_value'] < 0.05:\n",
    "                print(f\"  **Statistically Significant (p < 0.05)**: Reject Null Hypothesis. \"\n",
    "                      f\"Distribution of '{category}' comments differs across video types.\")\n",
    "            else:\n",
    "                print(f\"  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. \"\n",
    "                      f\"No strong evidence that distribution of '{category}' comments differs across video types.\")\n",
    "                \n",
    "            print(\"\\n  Category Presence Indicators by Source:\")\n",
    "            for source_id, data in result['groups_data'].items():\n",
    "                print(f\"    Source {source_id}:  Present Count = {sum(data)}, \"\n",
    "                      f\"Absent Count = {len(data) - sum(data)}, Total = {len(data)}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "    return kruskal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "SC9i4vUrTlx5sKxvoGhXch",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Test Results for Category Distribution across Video Types:\n",
      "\n",
      "Category: Vocal Performance\n",
      "  Kruskal-Wallis H-statistic: 1.4940\n",
      "  P-value: 0.4738\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Vocal Performance' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 45, Absent Count = 196, Total = 241\n",
      "    Source 2:  Present Count = 1861, Absent Count = 9923, Total = 11784\n",
      "    Source 3:  Present Count = 416, Absent Count = 2187, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Visual Performance\n",
      "  Kruskal-Wallis H-statistic: 1.3686\n",
      "  P-value: 0.5044\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Visual Performance' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 2, Absent Count = 239, Total = 241\n",
      "    Source 2:  Present Count = 87, Absent Count = 11697, Total = 11784\n",
      "    Source 3:  Present Count = 25, Absent Count = 2578, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Visual Performance - Stage Presence\n",
      "  Kruskal-Wallis H-statistic: 0.7527\n",
      "  P-value: 0.6864\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Visual Performance - Stage Presence' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 0, Absent Count = 241, Total = 241\n",
      "    Source 2:  Present Count = 15, Absent Count = 11769, Total = 11784\n",
      "    Source 3:  Present Count = 2, Absent Count = 2601, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Visual Performance - Gestures\n",
      "  Kruskal-Wallis H-statistic: 0.3692\n",
      "  P-value: 0.8314\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Visual Performance - Gestures' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 0, Absent Count = 241, Total = 241\n",
      "    Source 2:  Present Count = 18, Absent Count = 11766, Total = 11784\n",
      "    Source 3:  Present Count = 4, Absent Count = 2599, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Visual Performance - Movement\n",
      "  Kruskal-Wallis H-statistic: 0.3961\n",
      "  P-value: 0.8203\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Visual Performance - Movement' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 0, Absent Count = 241, Total = 241\n",
      "    Source 2:  Present Count = 6, Absent Count = 11778, Total = 11784\n",
      "    Source 3:  Present Count = 2, Absent Count = 2601, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Technical Production\n",
      "  Kruskal-Wallis H-statistic: 5.0231\n",
      "  P-value: 0.0811\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Technical Production' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 2, Absent Count = 239, Total = 241\n",
      "    Source 2:  Present Count = 33, Absent Count = 11751, Total = 11784\n",
      "    Source 3:  Present Count = 13, Absent Count = 2590, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Technical Production - Video Quality\n",
      "  Kruskal-Wallis H-statistic: 2.0476\n",
      "  P-value: 0.3592\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Technical Production - Video Quality' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 1, Absent Count = 240, Total = 241\n",
      "    Source 2:  Present Count = 19, Absent Count = 11765, Total = 11784\n",
      "    Source 3:  Present Count = 7, Absent Count = 2596, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Technical Production - Camera Work\n",
      "  Kruskal-Wallis H-statistic: 0.1926\n",
      "  P-value: 0.9082\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Technical Production - Camera Work' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 0, Absent Count = 241, Total = 241\n",
      "    Source 2:  Present Count = 8, Absent Count = 11776, Total = 11784\n",
      "    Source 3:  Present Count = 2, Absent Count = 2601, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Technical Production - Lighting\n",
      "  Kruskal-Wallis H-statistic: 1.4306\n",
      "  P-value: 0.4890\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Technical Production - Lighting' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 0, Absent Count = 241, Total = 241\n",
      "    Source 2:  Present Count = 1, Absent Count = 11783, Total = 11784\n",
      "    Source 3:  Present Count = 1, Absent Count = 2602, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Overall Impression\n",
      "  Kruskal-Wallis H-statistic: 2.4069\n",
      "  P-value: 0.3002\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Overall Impression' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 17, Absent Count = 224, Total = 241\n",
      "    Source 2:  Present Count = 962, Absent Count = 10822, Total = 11784\n",
      "    Source 3:  Present Count = 234, Absent Count = 2369, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Overall Impression - Positive\n",
      "  Kruskal-Wallis H-statistic: 12.2571\n",
      "  P-value: 0.0022\n",
      "  **Statistically Significant (p < 0.05)**: Reject Null Hypothesis. Distribution of 'Overall Impression - Positive' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 75, Absent Count = 166, Total = 241\n",
      "    Source 2:  Present Count = 3145, Absent Count = 8639, Total = 11784\n",
      "    Source 3:  Present Count = 776, Absent Count = 1827, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Overall Impression - Negative\n",
      "  Kruskal-Wallis H-statistic: 51.3929\n",
      "  P-value: 0.0000\n",
      "  **Statistically Significant (p < 0.05)**: Reject Null Hypothesis. Distribution of 'Overall Impression - Negative' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 5, Absent Count = 236, Total = 241\n",
      "    Source 2:  Present Count = 572, Absent Count = 11212, Total = 11784\n",
      "    Source 3:  Present Count = 47, Absent Count = 2556, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Overall Impression - Neutral\n",
      "  Kruskal-Wallis H-statistic: 2.6443\n",
      "  P-value: 0.2666\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Overall Impression - Neutral' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 0, Absent Count = 241, Total = 241\n",
      "    Source 2:  Present Count = 10, Absent Count = 11774, Total = 11784\n",
      "    Source 3:  Present Count = 5, Absent Count = 2598, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Engagement/Connection\n",
      "  Kruskal-Wallis H-statistic: 3.0866\n",
      "  P-value: 0.2137\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Engagement/Connection' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 11, Absent Count = 230, Total = 241\n",
      "    Source 2:  Present Count = 663, Absent Count = 11121, Total = 11784\n",
      "    Source 3:  Present Count = 167, Absent Count = 2436, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Engagement/Connection - Personal Connection\n",
      "  Kruskal-Wallis H-statistic: 0.2372\n",
      "  P-value: 0.8882\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Engagement/Connection - Personal Connection' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 19, Absent Count = 222, Total = 241\n",
      "    Source 2:  Present Count = 925, Absent Count = 10859, Total = 11784\n",
      "    Source 3:  Present Count = 197, Absent Count = 2406, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Engagement/Connection - Artist Connection\n",
      "  Kruskal-Wallis H-statistic: 1.8303\n",
      "  P-value: 0.4005\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Engagement/Connection - Artist Connection' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 1, Absent Count = 240, Total = 241\n",
      "    Source 2:  Present Count = 61, Absent Count = 11723, Total = 11784\n",
      "    Source 3:  Present Count = 19, Absent Count = 2584, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Olympic games\n",
      "  Kruskal-Wallis H-statistic: 3.5663\n",
      "  P-value: 0.1681\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Olympic games' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 13, Absent Count = 228, Total = 241\n",
      "    Source 2:  Present Count = 547, Absent Count = 11237, Total = 11784\n",
      "    Source 3:  Present Count = 143, Absent Count = 2460, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Implicit Visual Influence\n",
      "  Kruskal-Wallis H-statistic: 5.1298\n",
      "  P-value: 0.0769\n",
      "  Not Statistically Significant (p >= 0.05): Fail to Reject Null Hypothesis. No strong evidence that distribution of 'Implicit Visual Influence' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 1, Absent Count = 240, Total = 241\n",
      "    Source 2:  Present Count = 7, Absent Count = 11777, Total = 11784\n",
      "    Source 3:  Present Count = 1, Absent Count = 2602, Total = 2603\n",
      "--------------------------------------------------\n",
      "Category: Playback usage\n",
      "  Kruskal-Wallis H-statistic: 92.1620\n",
      "  P-value: 0.0000\n",
      "  **Statistically Significant (p < 0.05)**: Reject Null Hypothesis. Distribution of 'Playback usage' comments differs across video types.\n",
      "\n",
      "  Category Presence Indicators by Source:\n",
      "    Source 1:  Present Count = 5, Absent Count = 236, Total = 241\n",
      "    Source 2:  Present Count = 695, Absent Count = 11089, Total = 11784\n",
      "    Source 3:  Present Count = 38, Absent Count = 2565, Total = 2603\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = perform_kruskal_wallis_test(df, category_dict)"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "openai",
     "source": "PIP"
    },
    {
     "name": "mplcursors",
     "source": "PIP",
     "version": "0.6"
    },
    {
     "name": "fuzzy-c-means",
     "source": "PIP",
     "version": "1.6.3"
    }
   ],
   "report_row_ids": [],
   "report_tabs": [
    {
     "id": "2ryQPXyaiaytO3HTXoZVwt",
     "name": "Report tab",
     "rows": [
      "WdamQYp5t4n7AQrRbHwBAO",
      "NrkwMz34Muhnvc6j6hhgBh",
      "feyxETL2MwvKME79Ez2zcx",
      "t6OlZoV2LHU4OL2hSxokp5",
      "z86LYFCLhBHFo8I0U5MSny",
      "dJGN6TcKDfW0qkgjdDPmEK",
      "yNzqboE7Kr1KIrgbk8FeaH",
      "P36kV1x6GlwuFyYprmsAl6",
      "KQRiXML38Orw2t4WbKa6Mr"
     ]
    }
   ],
   "version": 4
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
